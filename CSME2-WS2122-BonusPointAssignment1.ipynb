{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSME2 Bonus Point Assignment 1\n",
    "\n",
    "<div style=\"text-align: right;font-size: 0.8em\">Document Version 1.0.0, released 01/12/2021</div>\n",
    "For detailed task instructions, please refer to the assignment PDF.\n",
    "\n",
    "DO NOT CLEAR THE OUTPUT of the notebook you are submitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import you need in this cell\n",
    "import numpy as np\n",
    "from sklearn.cluster import kmeans_plusplus, KMeans\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "__Task A.1__ Load the data into the following numpy arrays. For the output, only use the first torque variable.\n",
    "Randomly split the data from the file ```sarcos_inv.mat``` into a training set (80%) and a validation set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "data = loadmat(path + '/data/sarcos_inv.mat')\n",
    "test_data = loadmat(path + '/data/sarcos_inv_test.mat')\n",
    "\n",
    "data_array = data['sarcos_inv']\n",
    "test_data_array = test_data['sarcos_inv_test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splits the data into train and validation data\n",
    "def split_data(array, percentage_train): # percentage_train defined as float\n",
    "    np.random.shuffle(array)\n",
    "    train, validation = array[:math.floor(array.shape[0] * percentage_train) ,:], array[math.floor(array.shape[0] * percentage_train):,:]\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output training data\n",
    "train, validation = split_data(data_array, 0.8)\n",
    "\n",
    "input_data = data_array[:, :21]\n",
    "output_data = data_array[:, 21:22]\n",
    "\n",
    "xs_train = train[:, :21]\n",
    "ys_train = train[:, 21:22]\n",
    "\n",
    "# Input and output validation data\n",
    "xs_valid = validation[:, :21]\n",
    "ys_valid = validation[:, 21:22]\n",
    "\n",
    "# Input and output test data\n",
    "xs_test = test_data_array[:, :21]\n",
    "ys_test = test_data_array[:, 21:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35587, 21)\n",
      "(35587, 1)\n",
      "(8897, 21)\n",
      "(8897, 1)\n",
      "(4449, 21)\n",
      "(4449, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check for yourself \n",
    "# The following should lead to output \n",
    "# (44484, 21)\n",
    "# (44484, 1)\n",
    "# (8897, 21)\n",
    "# (8897, 1)\n",
    "# (4449, 21)\n",
    "# (4449, 1)\n",
    "print(xs_train.shape)\n",
    "print(ys_train.shape)\n",
    "print(xs_valid.shape)\n",
    "print(ys_valid.shape)\n",
    "print(xs_test.shape)\n",
    "print(ys_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task A.2__ Standardize the data such that\n",
    "1. Training inputs have mean 0\n",
    "2. Each training input variable has variance 1\n",
    "3. The training outputs have mean 0\n",
    "4. Apply the same transformation to the validation and test data\n",
    "\n",
    "Implement this manually, i.e., do not use a ready scaler like the one provided by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35587, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 975,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean and std of the training data\n",
    "input_mean = np.mean(xs_train, axis=0)\n",
    "input_std = np.std(xs_train, axis=0)\n",
    "output_mean = np.mean(ys_train, axis=0)\n",
    "\n",
    "# Store the standardized data in the following variables\n",
    "xs_train_std = (xs_train - input_mean) / input_std\n",
    "ys_train_std = ys_train - output_mean\n",
    "\n",
    "print(xs_train.shape)\n",
    "\n",
    "xs_valid_std = (xs_valid - input_mean) / input_std\n",
    "ys_valid_std = ys_valid - output_mean\n",
    "\n",
    "xs_test_std = (xs_test - input_mean) / input_std\n",
    "ys_test_std = ys_test - output_mean\n",
    "xs_test_std.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7988736604700613e-17\n",
      "1.0829751872208343e-15\n",
      "-0.0031732117530427063\n",
      "0.1987224037964787\n",
      "-0.0015470586122085716\n",
      "0.07801142839810273\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.99941944 0.99560469 0.99031795 1.00475838 0.98202453 0.99057856\n",
      " 0.98962848 1.04329953 0.98648227 1.01507856 1.01233076 0.97888543\n",
      " 0.99605626 1.01274888 1.04355923 1.0075977  1.01756782 1.00041788\n",
      " 0.9999016  1.01836687 1.01063379]\n",
      "[0.9998744  0.99869108 0.99799683 0.99987941 0.99726481 0.99929238\n",
      " 0.99628287 1.01155323 1.00516321 1.00175004 1.00261741 0.99621362\n",
      " 0.99665721 1.00328967 1.00272614 0.98505808 1.02386997 1.00787492\n",
      " 1.0053608  1.00520189 1.00324081]\n"
     ]
    }
   ],
   "source": [
    "# Check for yourself\n",
    "# The following should lead to (roughly) six zeros and three arrays with (approximately) ones\n",
    "print(np.mean(xs_train_std))\n",
    "print(np.mean(ys_train_std))\n",
    "print(np.mean(xs_valid_std))\n",
    "print(np.mean(ys_valid_std))\n",
    "print(np.mean(xs_test_std))\n",
    "print(np.mean(ys_test_std))\n",
    "\n",
    "print(np.var(xs_train_std, axis=0))\n",
    "print(np.var(xs_valid_std, axis=0))\n",
    "print(np.var(xs_test_std, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task A.3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A.3.a\n",
    "# Implement a function estimating the variance\n",
    "def my_variance(xs):\n",
    "    \"\"\"Calculate the empirical variance of a given vector of scalars\n",
    "    \n",
    "    Arguments\n",
    "    xs      1d numpy array\n",
    "    \n",
    "    Returns\n",
    "    The empirical variance of the provided vector\n",
    "    \"\"\"\n",
    "    mean = np.sum(xs)/xs.shape[0]\n",
    "    variance = np.sum((xs-mean)**2)/xs.shape[0]\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413.454117818437"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task A.3.b\n",
    "# Calculate the variance of ys_train_std using your function my_variance\n",
    "var_ys_train = my_variance(ys_train_std)\n",
    "var_ys_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A.3.c\n",
    "# Implement a function calculating the SMSE between two 1d numpy arrays given a normalizing factor\n",
    "def my_smse(z1, z2, s):\n",
    "    \"\"\"Calculate the Standardized Mean Squared Error (SMSE)\n",
    "    \n",
    "    Arguments\n",
    "    z1      1d numpy array (usually the predictions)\n",
    "    z2      1d numpy array (usually the test data)\n",
    "    s       Normalization factor (usually the variance of the test data)\n",
    "    \n",
    "    Returns\n",
    "    The SMSE of the provided data\n",
    "    \"\"\"\n",
    "    # Your implementation\n",
    "    calc_sum = np.sum((z1-z2)**2) # substracts the arrays form each other, squares them and then sums up the values \n",
    "    smse = 1/(z1.shape[0] * s) * calc_sum\n",
    "    return smse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "### Simple linear regression\n",
    "__Task A.4__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07535841224617751"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This variable should contain the weights corresponding to simple linear regression (LS criterion, no bias term)\n",
    "\n",
    "vector = np.ones(xs_train_std.shape[0]) # creates vector only containing ones \n",
    "phi = np.c_[vector, xs_train_std] # creates the basis function \n",
    "w_lr = np.linalg.inv(phi.T @ phi) @ phi.T @ ys_train_std\n",
    "\n",
    "# This variable should contain the predictions using w_lr on the test data\n",
    "vector2 = np.ones(xs_valid_std.shape[0]) # creates vector only containing ones matching the size of xs_valid_std\n",
    "phi_valid = np.c_[vector2, xs_valid_std]\n",
    "ys_pred_valid = phi_valid @ w_lr.reshape([-1,1])\n",
    "\n",
    "# This should contain the resulting smse\n",
    "smse_lr = my_smse(ys_pred_valid, ys_valid_std, var_ys_train)\n",
    "smse_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with polynomial features\n",
    "__Task A.5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A.5.a\n",
    "def my_poly_features(xs, degree):\n",
    "    \"\"\"Generates polynomial features from given data\n",
    "    \n",
    "    The polynomial features should include monomials (i.e., x_i, x_i**2 etc)\n",
    "    and interaction terms (x_1*x_2 etc), but no repetitions.\n",
    "    The order of the samples should not be changed through the transformation.\n",
    "    \n",
    "    Arguments\n",
    "    xs      2d numpy array of shape (N,D) containing N samples of dimension D\n",
    "    degree  Maximum degree of polynomials to be considered\n",
    "    \n",
    "    Returns\n",
    "    An (N,M) numpy array containing the transformed input\n",
    "    \"\"\"\n",
    "    # Your implementation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks A.5.b\n",
    "# This variable should contain the weights corresponding to linear regression using polynomial features up to degree 2 and 3\n",
    "# w_poly2 =\n",
    "# w_poly3\n",
    "\n",
    "# This variable should contain the predictions using w_poly2 and w_poly3 on the validation data\n",
    "# ys_pred_poly2_valid = \n",
    "# ys_pred_poly3_valid = \n",
    "\n",
    "# This should contain the resulting smse\n",
    "# smse_poly2 = my_smse(ys_pred_poly2_valid, ys_valid_std, var_ys_train)\n",
    "# smse_poly3 = my_smse(ys_pred_poly3_valid, ys_valid_std, var_ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "__Task B.1__ Implement the basic $K$-Means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kmeans(xs, init_centers, n_iter):\n",
    "    \"\"\"Runs the K-Means algorithm from a given initialization\n",
    "    \n",
    "    Arguments\n",
    "    xs            2d numpy array of shape (N,D) containing N samples of dimension D\n",
    "    init_centers  2d numpy array of shape (K,D) containing the initial cluster centers\n",
    "    n_iter        Number of iterations of the K-Means algorithm\n",
    "    \n",
    "    Returns\n",
    "    An (K,D) numpy array containing the final cluster centers\n",
    "    \"\"\"\n",
    "    # Your implementation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task B.2__ Generate test data set and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data of shape (100,2)\n",
    "# xs_cluster_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task B.3__ Run your $K$-Means algorithm on the test data for $K=2,3,4,5$ clusters and plot the final cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use kmeans_plusplus(xs_cluster_test, K, random_state=0) for initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Basis Function Network\n",
    "__Task C.1__ Find $K=100$ cluster centers using $K$-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This 100x21 numpy array should contain the cluster centers\n",
    "# xs_centers = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task C.2__ Implement the Gaussian basis functions and transform the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_train_gauss = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task C.3__ Run simple linear regression on the transformed data and evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should contain the resulting predictions on the validation data set\n",
    "# ys_pred_gauss_valid = \n",
    "\n",
    "# This should contain the corresponding SMSE\n",
    "# smse_gauss = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Open task__ Can you improve the performance of the RBF network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task C.4__ Evaluate your final model (either the one from Task C.3 or your improved model from the open task) on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should contain the predictions on the test data set\n",
    "# ys_pred_test = \n",
    "\n",
    "# This should contain the resulting SMSE on the test data\n",
    "# smse_test = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
